{
  "metadata": {
    "name": "New JSNB",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Face Recognition</title>\n  <!-- Include Cropper.js library -->\n  <link rel=\"stylesheet\" href=\"https://unpkg.com/cropperjs/dist/cropper.css\">\n  <style>\n   #container {\n      display: flex;\n      justify-content: space-between;\n      width: 800px; /* Adjust the total width as needed */\n      margin: auto; /* Center the container */\n    }\n\n    #videoContainer {\n      position: relative;\n      width: 240px; /* Adjust to your video stream width */\n      height: 240px; /* Adjust to your video stream height */\n    }\n\n    #video, #canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n    }\n  </style>\n</head>\n<body>\n  <div id=\"container\">\n    <div id=\"videoContainer\">\n      \t\t\t<video id=\"video\" width=\"240\" height=\"180\" autoplay></video>\n         \n            <canvas id=\"canvas\" width=\"240\" height=\"240\"></canvas>\n     </div>\n  \n  </div>\n  <div>\n \t\t <button id=\"captureBtn\">Capture</button>\n\t\t <button id=\"processBtn\">Process</button>\n  </div>\n\n</body>\n</html>\n\n",
      "status": "",
      "output": "\n\n\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Face Recognition</title>\n  <!-- Include Cropper.js library -->\n  <link rel=\"stylesheet\" href=\"https://unpkg.com/cropperjs/dist/cropper.css\"><style class=\"darkreader darkreader--cors\" media=\"screen\">.cropper-container {\n  direction: ltr;\n  font-size: 0;\n  line-height: 0;\n  position: relative;\n  -ms-touch-action: none;\n      touch-action: none;\n  -webkit-touch-callout: none;\n  -webkit-user-select: none;\n     -moz-user-select: none;\n      -ms-user-select: none;\n          user-select: none;\n}\n\n.cropper-container img {\n    backface-visibility: hidden;\n    display: block;\n    height: 100%;\n    image-orientation: 0deg;\n    max-height: none !important;\n    max-width: none !important;\n    min-height: 0 !important;\n    min-width: 0 !important;\n    width: 100%;\n  }\n\n.cropper-wrap-box,\n.cropper-canvas,\n.cropper-drag-box,\n.cropper-crop-box,\n.cropper-modal {\n  bottom: 0;\n  left: 0;\n  position: absolute;\n  right: 0;\n  top: 0;\n}\n\n.cropper-wrap-box,\n.cropper-canvas {\n  overflow: hidden;\n}\n\n.cropper-drag-box {\n  background-color: #fff;\n  opacity: 0;\n}\n\n.cropper-modal {\n  background-color: #000;\n  opacity: 0.5;\n}\n\n.cropper-view-box {\n  display: block;\n  height: 100%;\n  outline: 1px solid #39f;\n  outline-color: rgba(51, 153, 255, 0.75);\n  overflow: hidden;\n  width: 100%;\n}\n\n.cropper-dashed {\n  border: 0 dashed #eee;\n  display: block;\n  opacity: 0.5;\n  position: absolute;\n}\n\n.cropper-dashed.dashed-h {\n    border-bottom-width: 1px;\n    border-top-width: 1px;\n    height: calc(100% / 3);\n    left: 0;\n    top: calc(100% / 3);\n    width: 100%;\n  }\n\n.cropper-dashed.dashed-v {\n    border-left-width: 1px;\n    border-right-width: 1px;\n    height: 100%;\n    left: calc(100% / 3);\n    top: 0;\n    width: calc(100% / 3);\n  }\n\n.cropper-center {\n  display: block;\n  height: 0;\n  left: 50%;\n  opacity: 0.75;\n  position: absolute;\n  top: 50%;\n  width: 0;\n}\n\n.cropper-center::before,\n  .cropper-center::after {\n    background-color: #eee;\n    content: ' ';\n    display: block;\n    position: absolute;\n  }\n\n.cropper-center::before {\n    height: 1px;\n    left: -3px;\n    top: 0;\n    width: 7px;\n  }\n\n.cropper-center::after {\n    height: 7px;\n    left: 0;\n    top: -3px;\n    width: 1px;\n  }\n\n.cropper-face,\n.cropper-line,\n.cropper-point {\n  display: block;\n  height: 100%;\n  opacity: 0.1;\n  position: absolute;\n  width: 100%;\n}\n\n.cropper-face {\n  background-color: #fff;\n  left: 0;\n  top: 0;\n}\n\n.cropper-line {\n  background-color: #39f;\n}\n\n.cropper-line.line-e {\n    cursor: ew-resize;\n    right: -3px;\n    top: 0;\n    width: 5px;\n  }\n\n.cropper-line.line-n {\n    cursor: ns-resize;\n    height: 5px;\n    left: 0;\n    top: -3px;\n  }\n\n.cropper-line.line-w {\n    cursor: ew-resize;\n    left: -3px;\n    top: 0;\n    width: 5px;\n  }\n\n.cropper-line.line-s {\n    bottom: -3px;\n    cursor: ns-resize;\n    height: 5px;\n    left: 0;\n  }\n\n.cropper-point {\n  background-color: #39f;\n  height: 5px;\n  opacity: 0.75;\n  width: 5px;\n}\n\n.cropper-point.point-e {\n    cursor: ew-resize;\n    margin-top: -3px;\n    right: -3px;\n    top: 50%;\n  }\n\n.cropper-point.point-n {\n    cursor: ns-resize;\n    left: 50%;\n    margin-left: -3px;\n    top: -3px;\n  }\n\n.cropper-point.point-w {\n    cursor: ew-resize;\n    left: -3px;\n    margin-top: -3px;\n    top: 50%;\n  }\n\n.cropper-point.point-s {\n    bottom: -3px;\n    cursor: s-resize;\n    left: 50%;\n    margin-left: -3px;\n  }\n\n.cropper-point.point-ne {\n    cursor: nesw-resize;\n    right: -3px;\n    top: -3px;\n  }\n\n.cropper-point.point-nw {\n    cursor: nwse-resize;\n    left: -3px;\n    top: -3px;\n  }\n\n.cropper-point.point-sw {\n    bottom: -3px;\n    cursor: nesw-resize;\n    left: -3px;\n  }\n\n.cropper-point.point-se {\n    bottom: -3px;\n    cursor: nwse-resize;\n    height: 20px;\n    opacity: 1;\n    right: -3px;\n    width: 20px;\n  }\n\n@media (min-width: 768px) {\n\n.cropper-point.point-se {\n      height: 15px;\n      width: 15px;\n  }\n    }\n\n@media (min-width: 992px) {\n\n.cropper-point.point-se {\n      height: 10px;\n      width: 10px;\n  }\n    }\n\n@media (min-width: 1200px) {\n\n.cropper-point.point-se {\n      height: 5px;\n      opacity: 0.75;\n      width: 5px;\n  }\n    }\n\n.cropper-point.point-se::before {\n    background-color: #39f;\n    bottom: -50%;\n    content: ' ';\n    display: block;\n    height: 200%;\n    opacity: 0;\n    position: absolute;\n    right: -50%;\n    width: 200%;\n  }\n\n.cropper-invisible {\n  opacity: 0;\n}\n\n.cropper-bg {\n  background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQAQMAAAAlPW0iAAAAA3NCSVQICAjb4U/gAAAABlBMVEXMzMz////TjRV2AAAACXBIWXMAAArrAAAK6wGCiw1aAAAAHHRFWHRTb2Z0d2FyZQBBZG9iZSBGaXJld29ya3MgQ1M26LyyjAAAABFJREFUCJlj+M/AgBVhF/0PAH6/D/HkDxOGAAAAAElFTkSuQmCC');\n}\n\n.cropper-hide {\n  display: block;\n  height: 0;\n  position: absolute;\n  width: 0;\n}\n\n.cropper-hidden {\n  display: none !important;\n}\n\n.cropper-move {\n  cursor: move;\n}\n\n.cropper-crop {\n  cursor: crosshair;\n}\n\n.cropper-disabled .cropper-drag-box,\n.cropper-disabled .cropper-face,\n.cropper-disabled .cropper-line,\n.cropper-disabled .cropper-point {\n  cursor: not-allowed;\n}</style><style class=\"darkreader darkreader--sync\" media=\"screen\"></style>\n  <style>\n   #container {\n      display: flex;\n      justify-content: space-between;\n      width: 800px; /* Adjust the total width as needed */\n      margin: auto; /* Center the container */\n    }\n\n    #videoContainer {\n      position: relative;\n      width: 240px; /* Adjust to your video stream width */\n      height: 240px; /* Adjust to your video stream height */\n    }\n\n    #video, #canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n    }\n  </style><style class=\"darkreader darkreader--sync\" media=\"screen\"></style>\n\n\n  <div id=\"container\">\n    <div id=\"videoContainer\">\n      \t\t\t<video id=\"video\" width=\"240\" height=\"180\" autoplay=\"\"></video>\n         \n            <canvas id=\"canvas\" width=\"240\" height=\"180\"></canvas>\n     </div>\n  \n  </div>\n  <div>\n \t\t <button id=\"captureBtn\">Capture</button>\n\t\t <button id=\"processBtn\">Process</button>\n  </div>\n\n\n\n\n",
      "type": "html"
    },
    {
      "code": "  import('https://unpkg.com/face-api.js@latest/dist/face-api.js')",
      "status": "[21]<br><span style=\"font-size:8px\">5ms<span></span></span>",
      "output": "{} <br>",
      "type": "code"
    },
    {
      "code": "\nPromise.all([\n faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/tiny_face_detector_model-weights_manifest.json'),\n  faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_landmark_68_model-weights_manifest.json'),\n  faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_recognition_model-weights_manifest.json'),\n faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_expression_model-weights_manifest.json')\n]).then(() => {\n  // Your code to handle the loaded models\n  console.log(\"Models loaded successfully\");\n  \n});",
      "status": "[22]<br><span style=\"font-size:8px\">319ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "var video = document.getElementById('video');     \nvar capture =  document.getElementById('captureBtn');   \nvar process =  document.getElementById('processBtn');   \n\n\ncapture.addEventListener(\"click\",()=>{\n// Access the camera andget video stream..\n      navigator.mediaDevices.getUserMedia({ video: true })\n        .then((cameraStream) => {\n          stream = cameraStream;\n          video.srcObject = cameraStream;\n        })\n        .catch((error) => {\n         show('Error accessing camera:', error);\n        });\n}\n)",
      "status": "[23]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "process.addEventListener('click', () => {\nconst canvas = document.getElementById('canvas');\n\n  const displaySize = { width: video.width, height: video.height }\n  \n  canvas.width = displaySize.width;\ncanvas.height = displaySize.height;\n  \n  faceapi.matchDimensions(canvas, displaySize)\n  setInterval(async () => {\n    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()\n    const resizedDetections = faceapi.resizeResults(detections, displaySize)\n    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)\n    faceapi.draw.drawDetections(canvas, resizedDetections)\n    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)\n    faceapi.draw.drawFaceExpressions(canvas, resizedDetections)\n  }, 100)\n})",
      "status": "[24]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "",
      "status": "[25]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/jsnb",
  "run_on_load": false
}