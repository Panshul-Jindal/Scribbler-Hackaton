{
  "metadata": {
    "name": "New JSNB",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>JARVIS - Virtual Assistant</title>\n    //<link rel=\"shortcut icon\" href=\"avatar.png\" type=\"image/x-icon\">\n    //<link rel=\"stylesheet\" href=\"style.css\">\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n\t\n\t  <style>\n\t  @import url(\"https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@100;200;300;400;500;600;700&display=swap\");\n\n* {\n  margin: 0;\n  padding: 0;\n  box-sizing: border-box;\n  font-family: \"Roboto Mono\", monospace;\n}\n\n.main {\n  min-height: 100vh;\n  position: relative;\n  width: 100%;\n  background: #000;\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  justify-content: center;\n}\n\n.main .image-container {\n  padding: 10px;\n}\n\n.main .image-container .image {\n  width: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n.main .image-container .image img {\n  width: 350px;\n  align-items: center;\n}\n\n\n.main .image-container h1 {\n  color: #00bcd4;\n  text-align: center;\n  margin-bottom: 10px;\n  font-size: 40px;\n}\n\n.main .image-container p {\n  color: #324042;\n  text-align: center;\n  margin-bottom: 40px;\n}\n\n.main .input {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  width: 40vw;\n  height: 50px;\n  border-radius: 20px;\n  background: rgb(202 253 255 / 50%);\n}\n\n.main .input .talk {\n  background: transparent;\n  outline: none;\n  border: none;\n  width: 50px;\n  height: 50px;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  font-size: 20px;\n  cursor: pointer;\n}\n\n.main .input .talk i {\n  font-size: 20px;\n  color: #aed0d0;\n}\n\n.main .input .content {\n  color: #aed0d0;\n  font-size: 15px;\n  margin-right: 20px;\n}\n\n\t  </style>\n</head>\n\n<body>\n    <section class=\"main\">\n        <div class=\"image-container\">\n            <div class=\"image\">\n                <img src=\"https://giphy.com/gifs/foc-ai-robot-future-of-content-58OujxlE7e19Mjv0gj\" alt=\"image\">\n            </div>\n            <h1>J A R V I S</h1>\n            <p>I'm a Virtual Assistant JARVIS, How may i help you?</p>\n        </div>\n        <div class=\"input\">\n            <button class=\"talk\"><i class=\"fas fa-microphone-alt\"></i></button>\n            <h1 class=\"content\"> Click here to speak</h1>\n        </div>\n    </section>\n    <script src=\"app.js\"></script>\n</body>\n\n</html>",
      "status": "",
      "output": "\n\n\n\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>JARVIS - Virtual Assistant</title>\n    //<link rel=\"shortcut icon\" href=\"avatar.png\" type=\"image/x-icon\">\n    //<link rel=\"stylesheet\" href=\"style.css\">\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css\">\n\t\n\t  <style>\n\t  @import url(\"https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@100;200;300;400;500;600;700&display=swap\");\n\n* {\n  margin: 0;\n  padding: 0;\n  box-sizing: border-box;\n  font-family: \"Roboto Mono\", monospace;\n}\n\n.main {\n  min-height: 100vh;\n  position: relative;\n  width: 100%;\n  background: #000;\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  justify-content: center;\n}\n\n.main .image-container {\n  padding: 10px;\n}\n\n.main .image-container .image {\n  width: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n}\n\n.main .image-container .image img {\n  width: 350px;\n  align-items: center;\n}\n\n\n.main .image-container h1 {\n  color: #00bcd4;\n  text-align: center;\n  margin-bottom: 10px;\n  font-size: 40px;\n}\n\n.main .image-container p {\n  color: #324042;\n  text-align: center;\n  margin-bottom: 40px;\n}\n\n.main .input {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  width: 40vw;\n  height: 50px;\n  border-radius: 20px;\n  background: rgb(202 253 255 / 50%);\n}\n\n.main .input .talk {\n  background: transparent;\n  outline: none;\n  border: none;\n  width: 50px;\n  height: 50px;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  font-size: 20px;\n  cursor: pointer;\n}\n\n.main .input .talk i {\n  font-size: 20px;\n  color: #aed0d0;\n}\n\n.main .input .content {\n  color: #aed0d0;\n  font-size: 15px;\n  margin-right: 20px;\n}\n\n\t  </style>\n\n\n\n    <section class=\"main\">\n        <div class=\"image-container\">\n            <div class=\"image\">\n                <img src=\"https://giphy.com/gifs/foc-ai-robot-future-of-content-58OujxlE7e19Mjv0gj\" alt=\"image\">\n            </div>\n            <h1>J A R V I S</h1>\n            <p>I'm a Virtual Assistant JARVIS, How may i help you?</p>\n        </div>\n        <div class=\"input\">\n            <button class=\"talk\"><i class=\"fas fa-microphone-alt\"></i></button>\n            <h1 class=\"content\"> Click here to speak</h1>\n        </div>\n    </section>\n    <script src=\"app.js\"></script>\n\n\n",
      "type": "html"
    },
    {
      "code": "const btn = document.querySelector('.talk')\nconst content = document.querySelector('.content')\n\nfunction speak(text){\n    const text_speak = new SpeechSynthesisUtterance(text);\n    text_speak.voice = speechSynthesis.getVoices()[3];\n    text_speak.rate =1;\n    text_speak.pitch=0.6;\n    text_speak.volume=2;\n\n        window.speechSynthesis.speak(text_speak);\n}\n\n\n\nfunction wishMe(){\n    var day = new Date();\n    var hour = day.getHours();\n\n    if(hour>=0 && hour<12){\n        speak(\"Good Morning Tony Stark...\")\n    }\n\n    else if(hour>12 && hour<17){\n        speak(\"Good Afternoon Tony Stark.\")\n    }\n\n    else{\n        speak(\"Good EveniningTony Stark...\")\n    }\n\n}\n\n\n\nwindow.onload = ()=>{\n    speak(\"Initializing JARVIS..\");\n\n    console.log(\"Window is Loaded\");\n    wishMe();\n};\n\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nconst recognition =  new SpeechRecognition();\n\n    recognition.onresult = (event)=>{\n        const currentIndex = event.resultIndex;\n        const transcript = event.results[currentIndex][0].transcript;\n        console.log(transcript);\n        content.textContent = transcript;\n        takeCommand(transcript.toLowerCase());\n\n    }\n\nbtn.addEventListener('click', ()=>{\n    content.textContent = \"Listening....\"\n    recognition.start();\n})\n\nfunction takeCommand(message){\n    if(message.includes('hey') || message.includes('hello')){\n        speak(\"Hello Sir, How May I Help You?\");\n    }\n    else if(message.includes(\"open google\")){\n        window.open(\"https://google.com\", \"_blank\");\n        speak(\"Opening Google...\")\n    }\n    else if(message.includes(\"open youtube\")){\n        window.open(\"https://youtube.com\", \"_blank\");\n        speak(\"Opening Youtube...\")\n    }\n    else if(message.includes(\"open facebook\")){\n        window.open(\"https://facebook.com\", \"_blank\");\n        speak(\"Opening Facebook...\")\n    }\n\n    else if(message.includes('what is') || message.includes('who is') || message.includes('what are')) {\n        window.open(`https://www.google.com/search?q=${message.replace(\" \", \"+\")}`, \"_blank\");\n        const finalText = \"This is what i found on internet regarding \" + message;\n\t    speak(finalText);\n  \n    }\nelse if(message.includes('chatgpt')){\n        window.open(\"https://chatgpt.com/\", \"_blank\");\n        speak(\"Opening Chatgpt\")\n    }\n  else if(message.includes('bitcoin')){\n        window.open(\"https://in.tradingview.com/\", \"_blank\");\n        speak(\"Opening Chart of BITCOIN\")\n    }\n  else if(message.includes('game')){\n        window.open(\"https://www.crazygames.com/\", \"_blank\");\n        speak(\"Opening Games...\")\n    }\n    else if(message.includes('wikipedia')) {\n        window.open(`https://en.wikipedia.org/wiki/${message.replace(\"wikipedia\", \"\")}`, \"_blank\");\n        const finalText = \"This is what i found on wikipedia regarding \" + message.replace(\"wikipedia\",\"\");\n        speak(finalText);\n    }\n\n    else if(message.includes('time')) {\n        const time = new Date().toLocaleString(undefined, {hour: \"numeric\", minute: \"numeric\"})\n        const finalText = time;\n        speak(finalText);\n    }\n\n    else if(message.includes('date')) {\n        const date = new Date().toLocaleString(undefined, {month: \"short\", day: \"numeric\"})\n        const finalText = date;\n        speak(finalText);\n    }\n\n    else if(message.includes('calculator')) {\n        window.open('Calculator:///')\n        const finalText = \"Opening Calculator\";\n        speak(finalText);\n    }\n\n    else {\n        window.open(`https://www.google.com/search?q=${message.replace(\" \", \"+\")}`, \"_blank\");\n        const finalText = \"I found some information for \" + message + \" on google\";\n        speak(finalText);\n    }\n}\n\n",
      "status": "[2]<br><span style=\"font-size:8px\">1ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "const text_speak = new SpeechSynthesisUtterance(\"Hello World\");\n text_speak.voice = speechSynthesis.getVoices()[3];\n    text_speak.rate =1;\n    text_speak.pitch=0.6;\n    text_speak.volume=2;\n\n window.speechSynthesis.speak(text_speak);\n",
      "status": "[3]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\nconst recognition =  new SpeechRecognition();\n\n    recognition.onresult = (event)=>{\n        const currentIndex = event.resultIndex;\n        const transcript = event.results[currentIndex][0].transcript;\n        console.log(transcript);\n\t  \tscrib.show(transcript);\n        //content.textContent = transcript;\n        //takeCommand(transcript.toLowerCase());\n\n    }\nrecognition.start()",
      "status": "[3]<br><span style=\"font-size:8px\">0ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n  <title>Document</title>\n\n\n  <style>\n    body {\n      margin: 0;\n      padding: 0;\n      width: 100vw;\n      height: 100vh;\n      display: flex;\n      justify-content: center;\n      align-items: center;\n    }\n\n    canvas {\n      position: absolute;\n    }\n  </style>\n\n\n</head>\n<body>\n  <video id=\"video\" width=\"720\" height=\"560\" autoplay muted></video>\n</body>\n</html>\n\n",
      "status": "",
      "output": "\n\n\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n  <title>Document</title>\n\n\n  <style>\n    body {\n      margin: 0;\n      padding: 0;\n      width: 100vw;\n      height: 100vh;\n      display: flex;\n      justify-content: center;\n      align-items: center;\n    }\n\n    canvas {\n      position: absolute;\n    }\n  </style><style class=\"darkreader darkreader--sync\" media=\"screen\"></style>\n\n\n\n\n  <video id=\"video\" width=\"720\" height=\"560\" autoplay=\"\" muted=\"\"></video>\n\n\n\n",
      "type": "html"
    },
    {
      "code": "  import('https://unpkg.com/face-api.js@latest/dist/face-api.js')",
      "status": "[4]<br><span style=\"font-size:8px\">252ms<span></span></span>",
      "output": "{} <br>",
      "type": "code"
    },
    {
      "code": "Promise.all([\n faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/tiny_face_detector_model-weights_manifest.json'),\n  faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_landmark_68_model-weights_manifest.json'),\n  faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_recognition_model-weights_manifest.json'),\n faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights/face_expression_model-weights_manifest.json')\n]).then(() => {\n  // Your code to handle the loaded models\n  console.log(\"Models loaded successfully\");\n  \n});",
      "status": "[5]<br><span style=\"font-size:8px\">405ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "if(scrib.isSandboxed()) alert(\"Plase take it out of sandbox by clicking the red button on top right corner\");\nvar video = document.getElementById('video');\n\nnavigator.mediaDevices.getUserMedia({ video: true })\n        .then((cameraStream) => {\n          stream = cameraStream;\n          video.srcObject = cameraStream;\n  \n  \n        })\n        .catch((error) => {\n         scrib.show('Error accessing camera:', error.message);\n        });\n\nvideo.addEventListener('play', () => {\n  const canvas = faceapi.createCanvasFromMedia(video)\n  document.body.append(canvas)\n  const displaySize = { width: video.width, height: video.height }\n  faceapi.matchDimensions(canvas, displaySize)\n  setInterval(async () => {\n    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()\n    const resizedDetections = faceapi.resizeResults(detections, displaySize)\n    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)\n    faceapi.draw.drawDetections(canvas, resizedDetections)\n    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)\n    faceapi.draw.drawFaceExpressions(canvas, resizedDetections)\n  }, 100)\n})\n\n",
      "status": "[7]<br><span style=\"font-size:8px\">5ms<span></span></span>",
      "output": "",
      "type": "code"
    },
    {
      "code": "",
      "status": "",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/jsnb",
  "run_on_load": false
}